{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfab802",
   "metadata": {},
   "source": [
    "# 02d_data_cleaning_create_clean_dataset:\n",
    "\n",
    "copy_all_excluded_images - Copies the bad images to outputs/all_excluded_images/ for manual inspection\n",
    "create_clean_dataset - Copies the good images to data/CleanPetImages/ for training\n",
    "verify clean dataset - verifies the copy was okay and the right images were excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00e047",
   "metadata": {},
   "source": [
    "### copy_all_excluded_images - Copies the bad images to outputs/all_excluded_images/ for manual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418be91",
   "metadata": {},
   "source": [
    "### Two exclusion files to read:\n",
    "\n",
    "clip_cleanup_exclusions.txt - Contains just file paths (one per line), same path format as the detailed file but without the scores/reasons columns. These are images flagged by CLIP cleaning that remain after good images were kept - i.e., the undesirable leftovers.\n",
    "exclude_list.txt - Contains file paths (one per line, no header). These are images that should be excluded from the project in general (from earlier cleaning stages like tiny images, duplicates, corrupted files, etc.).\n",
    "\n",
    "The script should:\n",
    "\n",
    "Read both files and collect all unique paths\n",
    "Copy all these excluded images to a review/inspection folder (preserving Cat/Dog subfolders)\n",
    "Handle the different formats (one has headers to skip, one doesn't)\n",
    "\n",
    "Let me create this script:Prepared to synthesize file exclusion logic and filtering requirementsWhat the script does:\n",
    "\n",
    "Reads clip_cleanup_exclusions.txt - Handles the same format as the detailed file but expects only paths (skips any lines starting with # or -)\n",
    "Reads exclude_list.txt - Simple one-path-per-line format, no header\n",
    "Combines both into a unique set (so duplicates between files aren't copied twice)\n",
    "Copies to all_excluded_images/ with Cat/Dog subfolders preserved\n",
    "Prints detailed breakdown showing:\n",
    "\n",
    "How many came from each file\n",
    "How many overlap between both files\n",
    "Copy success/failure counts\n",
    "Final counts by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c041cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f8b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: C:\\AWrk\\cats_dogs_project\\outputs\\clip_cleanup_exclusions.txt not found\n",
      "Read 36 paths from exclude_list.txt\n",
      "\n",
      "Total unique paths to copy: 36\n",
      "\n",
      "======================================================================\n",
      "COPY ALL EXCLUDED IMAGES FOR INSPECTION\n",
      "======================================================================\n",
      "\n",
      "SOURCE FILES:\n",
      "  CLIP cleanup exclusions: C:\\AWrk\\cats_dogs_project\\outputs\\clip_cleanup_exclusions.txt\n",
      "    Paths in file: 0\n",
      "  General exclude list:    C:\\AWrk\\cats_dogs_project\\outputs\\exclude_list.txt\n",
      "    Paths in file: 36\n",
      "\n",
      "BREAKDOWN:\n",
      "  Only in CLIP cleanup:    0\n",
      "  Only in general exclude: 36\n",
      "  In both files:           0\n",
      "  Total unique:            36\n",
      "\n",
      "RESULTS:\n",
      "  Successfully copied: 36\n",
      "  Errors:              0\n",
      "\n",
      "DESTINATION: C:\\AWrk\\cats_dogs_project\\outputs\\all_excluded_images\n",
      "  Cats: 22\n",
      "  Dogs: 14\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "base_path = Path(r\"C:\\AWrk\\cats_dogs_project\")\n",
    "outputs_folder = base_path / \"outputs\"\n",
    "\n",
    "# Exclusion files\n",
    "clip_cleanup_file = outputs_folder / \"clip_cleanup_exclusions.txt\"\n",
    "general_exclude_file = outputs_folder / \"exclude_list.txt\"\n",
    "\n",
    "# Destination folder for inspection\n",
    "dest_folder = outputs_folder / \"all_excluded_images\"\n",
    "\n",
    "# Source image folders\n",
    "cat_folder = base_path / \"data\" / \"PetImages\" / \"Cat\"\n",
    "dog_folder = base_path / \"data\" / \"PetImages\" / \"Dog\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE DESTINATION FOLDER\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "(dest_folder / \"Cat\").mkdir(exist_ok=True)\n",
    "(dest_folder / \"Dog\").mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HELPER FUNCTION TO PARSE PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def extract_category_and_filename(rel_path):\n",
    "    \"\"\"\n",
    "    Extract category (Cat/Dog) and filename from a relative path.\n",
    "    Handles paths like: ..\\data\\PetImages\\Cat\\10029.jpg\n",
    "    \"\"\"\n",
    "    path_parts = rel_path.replace(\"\\\\\", \"/\").split(\"/\")\n",
    "    # Find Cat or Dog in the path\n",
    "    for i, part in enumerate(path_parts):\n",
    "        if part in (\"Cat\", \"Dog\"):\n",
    "            category = part\n",
    "            filename = path_parts[i + 1] if i + 1 < len(path_parts) else None\n",
    "            return category, filename\n",
    "    return None, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# READ CLIP CLEANUP EXCLUSIONS (paths only, may have header)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "clip_paths = set()\n",
    "\n",
    "if clip_cleanup_file.exists():\n",
    "    with open(clip_cleanup_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip empty lines and header lines\n",
    "            if not line or line.startswith(\"#\") or line.startswith(\"-\"):\n",
    "                continue\n",
    "            # Take first column if tab-separated, otherwise whole line\n",
    "            path = line.split(\"\\t\")[0].strip()\n",
    "            if path and \".jpg\" in path.lower():\n",
    "                clip_paths.add(path)\n",
    "    print(f\"Read {len(clip_paths)} paths from clip_cleanup_exclusions.txt\")\n",
    "else:\n",
    "    print(f\"WARNING: {clip_cleanup_file} not found\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# READ GENERAL EXCLUDE LIST (one path per line, no header)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "general_paths = set()\n",
    "\n",
    "if general_exclude_file.exists():\n",
    "    with open(general_exclude_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and \".jpg\" in line.lower():\n",
    "                general_paths.add(line)\n",
    "    print(f\"Read {len(general_paths)} paths from exclude_list.txt\")\n",
    "else:\n",
    "    print(f\"WARNING: {general_exclude_file} not found\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# COMBINE AND COPY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "all_paths = clip_paths.union(general_paths)\n",
    "print(f\"\\nTotal unique paths to copy: {len(all_paths)}\")\n",
    "\n",
    "# Track results\n",
    "copied = 0\n",
    "errors = []\n",
    "from_clip = 0\n",
    "from_general = 0\n",
    "from_both = 0\n",
    "\n",
    "for rel_path in sorted(all_paths):\n",
    "    category, filename = extract_category_and_filename(rel_path)\n",
    "    \n",
    "    if not category or not filename:\n",
    "        errors.append(f\"Could not parse path: {rel_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Track source\n",
    "    in_clip = rel_path in clip_paths\n",
    "    in_general = rel_path in general_paths\n",
    "    if in_clip and in_general:\n",
    "        from_both += 1\n",
    "    elif in_clip:\n",
    "        from_clip += 1\n",
    "    else:\n",
    "        from_general += 1\n",
    "    \n",
    "    # Build source path\n",
    "    if category == \"Cat\":\n",
    "        source = cat_folder / filename\n",
    "    else:\n",
    "        source = dog_folder / filename\n",
    "    \n",
    "    # Build destination path\n",
    "    dest = dest_folder / category / filename\n",
    "    \n",
    "    # Copy the file\n",
    "    try:\n",
    "        if source.exists():\n",
    "            shutil.copy2(source, dest)\n",
    "            copied += 1\n",
    "        else:\n",
    "            errors.append(f\"File not found: {source}\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error copying {source}: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"COPY ALL EXCLUDED IMAGES FOR INSPECTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"SOURCE FILES:\")\n",
    "print(f\"  CLIP cleanup exclusions: {clip_cleanup_file}\")\n",
    "print(f\"    Paths in file: {len(clip_paths)}\")\n",
    "print(f\"  General exclude list:    {general_exclude_file}\")\n",
    "print(f\"    Paths in file: {len(general_paths)}\")\n",
    "print()\n",
    "print(\"BREAKDOWN:\")\n",
    "print(f\"  Only in CLIP cleanup:    {from_clip}\")\n",
    "print(f\"  Only in general exclude: {from_general}\")\n",
    "print(f\"  In both files:           {from_both}\")\n",
    "print(f\"  Total unique:            {len(all_paths)}\")\n",
    "print()\n",
    "print(\"RESULTS:\")\n",
    "print(f\"  Successfully copied: {copied}\")\n",
    "print(f\"  Errors:              {len(errors)}\")\n",
    "print()\n",
    "print(f\"DESTINATION: {dest_folder}\")\n",
    "\n",
    "# Count by category in destination\n",
    "cat_count = len(list((dest_folder / \"Cat\").glob(\"*.jpg\")))\n",
    "dog_count = len(list((dest_folder / \"Dog\").glob(\"*.jpg\")))\n",
    "print(f\"  Cats: {cat_count}\")\n",
    "print(f\"  Dogs: {dog_count}\")\n",
    "\n",
    "if errors:\n",
    "    print()\n",
    "    print(\"ERRORS:\")\n",
    "    for err in errors[:30]:\n",
    "        print(f\"  {err}\")\n",
    "    if len(errors) > 30:\n",
    "        print(f\"  ... and {len(errors) - 30} more\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f61349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86 rejected images in clip_exclude_details_v3plus.txt\n",
      "\n",
      "======================================================================\n",
      "COPY CLIP REJECTED IMAGES FOR MANUAL REVIEW\n",
      "======================================================================\n",
      "\n",
      "Source file: C:\\AWrk\\cats_dogs_project\\outputs\\clip_exclude_details_v3plus.txt\n",
      "Destination: C:\\AWrk\\cats_dogs_project\\outputs\\clip_rejected_for_review\n",
      "\n",
      "Images in file:     86\n",
      "Successfully copied: 86\n",
      "Errors:              0\n",
      "\n",
      "Cats: 44\n",
      "Dogs: 42\n",
      "Total: 86\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "base_path = Path(r\"C:\\AWrk\\cats_dogs_project\")\n",
    "outputs_folder = base_path / \"outputs\"\n",
    "\n",
    "# Input: CLIP filter results (for review)\n",
    "clip_results_file = outputs_folder / \"clip_exclude_details_v3plus.txt\"\n",
    "\n",
    "# Output: Folder to visually inspect rejected images\n",
    "review_folder = outputs_folder / \"clip_rejected_for_review\"\n",
    "\n",
    "# Source image folders\n",
    "cat_folder = base_path / \"data\" / \"PetImages\" / \"Cat\"\n",
    "dog_folder = base_path / \"data\" / \"PetImages\" / \"Dog\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE DESTINATION FOLDERS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "review_folder.mkdir(parents=True, exist_ok=True)\n",
    "(review_folder / \"Cat\").mkdir(exist_ok=True)\n",
    "(review_folder / \"Dog\").mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HELPER FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def extract_category_and_filename(rel_path):\n",
    "    \"\"\"Extract category (Cat/Dog) and filename from a path.\"\"\"\n",
    "    path_parts = rel_path.replace(\"\\\\\", \"/\").split(\"/\")\n",
    "    for i, part in enumerate(path_parts):\n",
    "        if part in (\"Cat\", \"Dog\"):\n",
    "            category = part\n",
    "            filename = path_parts[i + 1] if i + 1 < len(path_parts) else None\n",
    "            return category, filename\n",
    "    return None, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# READ CLIP RESULTS AND COPY IMAGES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "paths_to_copy = []\n",
    "\n",
    "with open(clip_results_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        # Skip empty lines and header lines\n",
    "        if not line or line.startswith(\"#\") or line.startswith(\"-\"):\n",
    "            continue\n",
    "        # First column is the path (tab-separated)\n",
    "        path = line.split(\"\\t\")[0].strip()\n",
    "        if path:\n",
    "            paths_to_copy.append(path)\n",
    "\n",
    "print(f\"Found {len(paths_to_copy)} rejected images in {clip_results_file.name}\")\n",
    "\n",
    "# Copy each image\n",
    "copied = 0\n",
    "errors = []\n",
    "\n",
    "for rel_path in paths_to_copy:\n",
    "    category, filename = extract_category_and_filename(rel_path)\n",
    "    \n",
    "    if not category or not filename:\n",
    "        errors.append(f\"Could not parse: {rel_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Build source path\n",
    "    if category == \"Cat\":\n",
    "        source = cat_folder / filename\n",
    "    else:\n",
    "        source = dog_folder / filename\n",
    "    \n",
    "    # Build destination\n",
    "    dest = review_folder / category / filename\n",
    "    \n",
    "    # Copy\n",
    "    try:\n",
    "        if source.exists():\n",
    "            shutil.copy2(source, dest)\n",
    "            copied += 1\n",
    "        else:\n",
    "            errors.append(f\"File not found: {source}\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error copying {source}: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"COPY CLIP REJECTED IMAGES FOR MANUAL REVIEW\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Source file: {clip_results_file}\")\n",
    "print(f\"Destination: {review_folder}\")\n",
    "print()\n",
    "print(f\"Images in file:     {len(paths_to_copy)}\")\n",
    "print(f\"Successfully copied: {copied}\")\n",
    "print(f\"Errors:              {len(errors)}\")\n",
    "print()\n",
    "\n",
    "# Count by category\n",
    "cat_count = len(list((review_folder / \"Cat\").glob(\"*.jpg\")))\n",
    "dog_count = len(list((review_folder / \"Dog\").glob(\"*.jpg\")))\n",
    "print(f\"Cats: {cat_count}\")\n",
    "print(f\"Dogs: {dog_count}\")\n",
    "print(f\"Total: {cat_count + dog_count}\")\n",
    "\n",
    "if errors:\n",
    "    print()\n",
    "    print(\"ERRORS:\")\n",
    "    for err in errors[:20]:\n",
    "        print(f\"  {err}\")\n",
    "    if len(errors) > 20:\n",
    "        print(f\"  ... and {len(errors) - 20} more\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed27f0",
   "metadata": {},
   "source": [
    "### create clean dataset\n",
    "\n",
    "**copy_all_excluded_images: Copy the Files that were **\n",
    "\n",
    "1. **Reads both exclusion files** and builds a set of filenames to exclude (stored separately for Cat and Dog)\n",
    "\n",
    "2. **Iterates through all images** in the original `PetImages/Cat` and `PetImages/Dog` folders\n",
    "\n",
    "3. **Copies only clean images** (those NOT in the exclusion sets) to `CleanPetImages/Cat` and `CleanPetImages/Dog`\n",
    "\n",
    "4. **Prints a detailed summary** showing:\n",
    "   - Original dataset counts\n",
    "   - How many were excluded\n",
    "   - Final clean dataset counts\n",
    "   - Verification of files actually in destination\n",
    "\n",
    "**Clear Dataset Output structure:**\n",
    "```\n",
    "C:\\AWrk\\cats_dogs_project\\data\\CleanPetImages\\\n",
    "Cat\\\n",
    "(clean cat images only)\n",
    "Dog\\\n",
    "(clean dog images only)\n",
    "\n",
    "Run the first script (`copy_all_excluded_images.py`) first if you want to inspect the rejected images, then run this one (`create_clean_dataset.py`) to create clean training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15bc02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 47 exclusions from clip_cleanup_exclusions.txt\n",
      "Read 36 exclusions from exclude_list.txt\n",
      "\n",
      "Total unique exclusions: 44 cats, 32 dogs\n",
      "\n",
      "Copying clean images...\n",
      "--------------------------------------------------\n",
      "Cat: 12456 copied, 44 excluded (from 12500 total)\n",
      "Dog: 12468 copied, 32 excluded (from 12500 total)\n",
      "\n",
      "======================================================================\n",
      "CLEAN DATASET CREATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "EXCLUSION SOURCES:\n",
      "  clip_cleanup_exclusions.txt: 47 paths\n",
      "  exclude_list.txt: 36 paths\n",
      "\n",
      "ORIGINAL DATASET:\n",
      "  Cats: 12,500\n",
      "  Dogs: 12,500\n",
      "  Total: 25,000\n",
      "\n",
      "EXCLUDED:\n",
      "  Cats: 44\n",
      "  Dogs: 32\n",
      "  Total: 76\n",
      "\n",
      "CLEAN DATASET:\n",
      "  Cats: 12,456\n",
      "  Dogs: 12,468\n",
      "  Total: 24,924\n",
      "\n",
      "DESTINATION: C:\\AWrk\\cats_dogs_project\\data\\CleanPetImages\n",
      "\n",
      "VERIFICATION (files in destination):\n",
      "  Cats: 12,456\n",
      "  Dogs: 12,468\n",
      "  Total: 24,924\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "base_path = Path(r\"C:\\AWrk\\cats_dogs_project\")\n",
    "outputs_folder = base_path / \"outputs\"\n",
    "\n",
    "# Exclusion files (TWO sources)\n",
    "clip_cleanup_file = outputs_folder / \"clip_cleanup_exclusions.txt\"  # Manual confirmations after review\n",
    "general_exclude_file = outputs_folder / \"exclude_list.txt\"          # Earlier exclusions (corrupted, duplicates)\n",
    "\n",
    "# Source image folders\n",
    "source_cat = base_path / \"data\" / \"PetImages\" / \"Cat\"\n",
    "source_dog = base_path / \"data\" / \"PetImages\" / \"Dog\"\n",
    "\n",
    "# Destination - clean dataset\n",
    "dest_folder = base_path / \"data\" / \"CleanPetImages\"\n",
    "dest_cat = dest_folder / \"Cat\"\n",
    "dest_dog = dest_folder / \"Dog\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CREATE DESTINATION FOLDERS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "dest_cat.mkdir(exist_ok=True)\n",
    "dest_dog.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HELPER FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def extract_category_and_filename(rel_path):\n",
    "    \"\"\"Extract category (Cat/Dog) and filename from a path.\"\"\"\n",
    "    path_parts = rel_path.replace(\"\\\\\", \"/\").split(\"/\")\n",
    "    for i, part in enumerate(path_parts):\n",
    "        if part in (\"Cat\", \"Dog\"):\n",
    "            category = part\n",
    "            filename = path_parts[i + 1] if i + 1 < len(path_parts) else None\n",
    "            return category, filename\n",
    "    return None, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# BUILD EXCLUSION SET FROM BOTH FILES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "excluded_files = {\"Cat\": set(), \"Dog\": set()}\n",
    "\n",
    "# Read clip_cleanup_exclusions.txt (manual confirmations)\n",
    "clip_count = 0\n",
    "if clip_cleanup_file.exists():\n",
    "    with open(clip_cleanup_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\") or line.startswith(\"-\"):\n",
    "                continue\n",
    "            path = line.split(\"\\t\")[0].strip()\n",
    "            if path:\n",
    "                category, filename = extract_category_and_filename(path)\n",
    "                if category and filename:\n",
    "                    excluded_files[category].add(filename.lower())\n",
    "                    clip_count += 1\n",
    "    print(f\"Read {clip_count} exclusions from clip_cleanup_exclusions.txt\")\n",
    "else:\n",
    "    print(f\"WARNING: {clip_cleanup_file} not found\")\n",
    "\n",
    "# Read exclude_list.txt (earlier exclusions)\n",
    "general_count = 0\n",
    "if general_exclude_file.exists():\n",
    "    with open(general_exclude_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                category, filename = extract_category_and_filename(line)\n",
    "                if category and filename:\n",
    "                    excluded_files[category].add(filename.lower())\n",
    "                    general_count += 1\n",
    "    print(f\"Read {general_count} exclusions from exclude_list.txt\")\n",
    "else:\n",
    "    print(f\"WARNING: {general_exclude_file} not found\")\n",
    "\n",
    "total_excluded_cats = len(excluded_files[\"Cat\"])\n",
    "total_excluded_dogs = len(excluded_files[\"Dog\"])\n",
    "print(f\"\\nTotal unique exclusions: {total_excluded_cats} cats, {total_excluded_dogs} dogs\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# COPY CLEAN IMAGES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def copy_clean_images(source_folder, dest_folder, excluded_set):\n",
    "    \"\"\"Copy all images except those in the exclusion set.\"\"\"\n",
    "    copied = 0\n",
    "    skipped = 0\n",
    "    errors = []\n",
    "    \n",
    "    all_images = list(source_folder.glob(\"*.jpg\"))\n",
    "    \n",
    "    for img_path in all_images:\n",
    "        filename_lower = img_path.name.lower()\n",
    "        \n",
    "        if filename_lower in excluded_set:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        dest_path = dest_folder / img_path.name\n",
    "        \n",
    "        try:\n",
    "            shutil.copy2(img_path, dest_path)\n",
    "            copied += 1\n",
    "        except Exception as e:\n",
    "            errors.append(f\"{img_path.name}: {e}\")\n",
    "    \n",
    "    return copied, skipped, errors, len(all_images)\n",
    "\n",
    "print(\"\\nCopying clean images...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Copy cats\n",
    "cat_copied, cat_skipped, cat_errors, cat_total = copy_clean_images(\n",
    "    source_cat, dest_cat, excluded_files[\"Cat\"]\n",
    ")\n",
    "print(f\"Cat: {cat_copied} copied, {cat_skipped} excluded (from {cat_total} total)\")\n",
    "\n",
    "# Copy dogs\n",
    "dog_copied, dog_skipped, dog_errors, dog_total = copy_clean_images(\n",
    "    source_dog, dest_dog, excluded_files[\"Dog\"]\n",
    ")\n",
    "print(f\"Dog: {dog_copied} copied, {dog_skipped} excluded (from {dog_total} total)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"CLEAN DATASET CREATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"EXCLUSION SOURCES:\")\n",
    "print(f\"  {clip_cleanup_file.name}: {clip_count} paths\")\n",
    "print(f\"  {general_exclude_file.name}: {general_count} paths\")\n",
    "print()\n",
    "print(\"ORIGINAL DATASET:\")\n",
    "print(f\"  Cats: {cat_total:,}\")\n",
    "print(f\"  Dogs: {dog_total:,}\")\n",
    "print(f\"  Total: {cat_total + dog_total:,}\")\n",
    "print()\n",
    "print(\"EXCLUDED:\")\n",
    "print(f\"  Cats: {cat_skipped:,}\")\n",
    "print(f\"  Dogs: {dog_skipped:,}\")\n",
    "print(f\"  Total: {cat_skipped + dog_skipped:,}\")\n",
    "print()\n",
    "print(\"CLEAN DATASET:\")\n",
    "print(f\"  Cats: {cat_copied:,}\")\n",
    "print(f\"  Dogs: {dog_copied:,}\")\n",
    "print(f\"  Total: {cat_copied + dog_copied:,}\")\n",
    "print()\n",
    "print(f\"DESTINATION: {dest_folder}\")\n",
    "\n",
    "# Verify\n",
    "final_cats = len(list(dest_cat.glob(\"*.jpg\")))\n",
    "final_dogs = len(list(dest_dog.glob(\"*.jpg\")))\n",
    "print()\n",
    "print(\"VERIFICATION (files in destination):\")\n",
    "print(f\"  Cats: {final_cats:,}\")\n",
    "print(f\"  Dogs: {final_dogs:,}\")\n",
    "print(f\"  Total: {final_cats + final_dogs:,}\")\n",
    "\n",
    "all_errors = cat_errors + dog_errors\n",
    "if all_errors:\n",
    "    print()\n",
    "    print(\"ERRORS:\")\n",
    "    for err in all_errors[:20]:\n",
    "        print(f\"  {err}\")\n",
    "    if len(all_errors) > 20:\n",
    "        print(f\"  ... and {len(all_errors) - 20} more\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac502baf",
   "metadata": {},
   "source": [
    "### verify clean dataset - Verify the clean dataset was created correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e25cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLEAN DATASET VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "TEST 1: No excluded files in clean dataset\n",
      "--------------------------------------------------\n",
      "  ✓ PASS: No excluded cats leaked into clean dataset\n",
      "  ✓ PASS: No excluded dogs leaked into clean dataset\n",
      "\n",
      "TEST 2: Count verification\n",
      "--------------------------------------------------\n",
      "  Cats: 12500 original - 44 excluded = 12456 expected\n",
      "        Clean dataset has: 12456\n",
      "  ✓ PASS: Cat count matches\n",
      "\n",
      "  Dogs: 12500 original - 32 excluded = 12468 expected\n",
      "        Clean dataset has: 12468\n",
      "  ✓ PASS: Dog count matches\n",
      "\n",
      "TEST 3: No unexpected files\n",
      "--------------------------------------------------\n",
      "  ✓ PASS: All clean cats came from original\n",
      "  ✓ PASS: All clean dogs came from original\n",
      "\n",
      "TEST 4: Exclusion files loaded correctly\n",
      "--------------------------------------------------\n",
      "  ✓ Found: clip_cleanup_exclusions.txt (76 total after combining)\n",
      "  ✓ Found: exclude_list.txt\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Original dataset:  12,500 cats + 12,500 dogs = 25,000 total\n",
      "Exclusions:        44 cats + 32 dogs = 76 total\n",
      "Clean dataset:     12,456 cats + 12,468 dogs = 24,924 total\n",
      "\n",
      "✓ ALL TESTS PASSED - Clean dataset is valid!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "base_path = Path(r\"C:\\AWrk\\cats_dogs_project\")\n",
    "outputs_folder = base_path / \"outputs\"\n",
    "\n",
    "# Exclusion files\n",
    "clip_cleanup_file = outputs_folder / \"clip_cleanup_exclusions.txt\"\n",
    "general_exclude_file = outputs_folder / \"exclude_list.txt\"\n",
    "\n",
    "# Original and clean datasets\n",
    "original_cat = base_path / \"data\" / \"PetImages\" / \"Cat\"\n",
    "original_dog = base_path / \"data\" / \"PetImages\" / \"Dog\"\n",
    "clean_cat = base_path / \"data\" / \"CleanPetImages\" / \"Cat\"\n",
    "clean_dog = base_path / \"data\" / \"CleanPetImages\" / \"Dog\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# HELPER FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def extract_category_and_filename(rel_path):\n",
    "    \"\"\"Extract category (Cat/Dog) and filename from a path.\"\"\"\n",
    "    path_parts = rel_path.replace(\"\\\\\", \"/\").split(\"/\")\n",
    "    for i, part in enumerate(path_parts):\n",
    "        if part in (\"Cat\", \"Dog\"):\n",
    "            category = part\n",
    "            filename = path_parts[i + 1] if i + 1 < len(path_parts) else None\n",
    "            return category, filename\n",
    "    return None, None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# BUILD EXCLUSION SET (same logic as create_clean_dataset.py)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "excluded_files = {\"Cat\": set(), \"Dog\": set()}\n",
    "\n",
    "# Read clip_cleanup_exclusions.txt\n",
    "if clip_cleanup_file.exists():\n",
    "    with open(clip_cleanup_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\") or line.startswith(\"-\"):\n",
    "                continue\n",
    "            path = line.split(\"\\t\")[0].strip()\n",
    "            if path:\n",
    "                category, filename = extract_category_and_filename(path)\n",
    "                if category and filename:\n",
    "                    excluded_files[category].add(filename.lower())\n",
    "\n",
    "# Read exclude_list.txt\n",
    "if general_exclude_file.exists():\n",
    "    with open(general_exclude_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                category, filename = extract_category_and_filename(line)\n",
    "                if category and filename:\n",
    "                    excluded_files[category].add(filename.lower())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# COUNT FILES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "original_cats = set(f.name.lower() for f in original_cat.glob(\"*.jpg\"))\n",
    "original_dogs = set(f.name.lower() for f in original_dog.glob(\"*.jpg\"))\n",
    "clean_cats = set(f.name.lower() for f in clean_cat.glob(\"*.jpg\"))\n",
    "clean_dogs = set(f.name.lower() for f in clean_dog.glob(\"*.jpg\"))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# VERIFICATION TESTS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLEAN DATASET VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "all_passed = True\n",
    "\n",
    "# Test 1: No excluded files should be in clean dataset\n",
    "print(\"TEST 1: No excluded files in clean dataset\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "leaked_cats = clean_cats.intersection(excluded_files[\"Cat\"])\n",
    "leaked_dogs = clean_dogs.intersection(excluded_files[\"Dog\"])\n",
    "\n",
    "if leaked_cats:\n",
    "    print(f\"  ❌ FAIL: {len(leaked_cats)} excluded cats found in clean dataset:\")\n",
    "    for f in sorted(leaked_cats)[:10]:\n",
    "        print(f\"       {f}\")\n",
    "    if len(leaked_cats) > 10:\n",
    "        print(f\"       ... and {len(leaked_cats) - 10} more\")\n",
    "    all_passed = False\n",
    "else:\n",
    "    print(f\"  ✓ PASS: No excluded cats leaked into clean dataset\")\n",
    "\n",
    "if leaked_dogs:\n",
    "    print(f\"  ❌ FAIL: {len(leaked_dogs)} excluded dogs found in clean dataset:\")\n",
    "    for f in sorted(leaked_dogs)[:10]:\n",
    "        print(f\"       {f}\")\n",
    "    if len(leaked_dogs) > 10:\n",
    "        print(f\"       ... and {len(leaked_dogs) - 10} more\")\n",
    "    all_passed = False\n",
    "else:\n",
    "    print(f\"  ✓ PASS: No excluded dogs leaked into clean dataset\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 2: Count verification\n",
    "print(\"TEST 2: Count verification\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "expected_cats = len(original_cats) - len(excluded_files[\"Cat\"].intersection(original_cats))\n",
    "expected_dogs = len(original_dogs) - len(excluded_files[\"Dog\"].intersection(original_dogs))\n",
    "\n",
    "print(f\"  Cats: {len(original_cats)} original - {len(excluded_files['Cat'].intersection(original_cats))} excluded = {expected_cats} expected\")\n",
    "print(f\"        Clean dataset has: {len(clean_cats)}\")\n",
    "if len(clean_cats) == expected_cats:\n",
    "    print(f\"  ✓ PASS: Cat count matches\")\n",
    "else:\n",
    "    print(f\"  ❌ FAIL: Cat count mismatch (diff: {len(clean_cats) - expected_cats})\")\n",
    "    all_passed = False\n",
    "\n",
    "print()\n",
    "print(f\"  Dogs: {len(original_dogs)} original - {len(excluded_files['Dog'].intersection(original_dogs))} excluded = {expected_dogs} expected\")\n",
    "print(f\"        Clean dataset has: {len(clean_dogs)}\")\n",
    "if len(clean_dogs) == expected_dogs:\n",
    "    print(f\"  ✓ PASS: Dog count matches\")\n",
    "else:\n",
    "    print(f\"  ❌ FAIL: Dog count mismatch (diff: {len(clean_dogs) - expected_dogs})\")\n",
    "    all_passed = False\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 3: No unexpected files (files in clean that weren't in original)\n",
    "print(\"TEST 3: No unexpected files\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "unexpected_cats = clean_cats - original_cats\n",
    "unexpected_dogs = clean_dogs - original_dogs\n",
    "\n",
    "if unexpected_cats:\n",
    "    print(f\"  ❌ FAIL: {len(unexpected_cats)} unexpected cats in clean dataset\")\n",
    "    all_passed = False\n",
    "else:\n",
    "    print(f\"  ✓ PASS: All clean cats came from original\")\n",
    "\n",
    "if unexpected_dogs:\n",
    "    print(f\"  ❌ FAIL: {len(unexpected_dogs)} unexpected dogs in clean dataset\")\n",
    "    all_passed = False\n",
    "else:\n",
    "    print(f\"  ✓ PASS: All clean dogs came from original\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 4: Check exclusion files were found\n",
    "print(\"TEST 4: Exclusion files loaded correctly\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if clip_cleanup_file.exists():\n",
    "    print(f\"  ✓ Found: {clip_cleanup_file.name} ({len(excluded_files['Cat']) + len(excluded_files['Dog'])} total after combining)\")\n",
    "else:\n",
    "    print(f\"  ⚠ WARNING: {clip_cleanup_file.name} not found\")\n",
    "\n",
    "if general_exclude_file.exists():\n",
    "    print(f\"  ✓ Found: {general_exclude_file.name}\")\n",
    "else:\n",
    "    print(f\"  ⚠ WARNING: {general_exclude_file.name} not found\")\n",
    "\n",
    "print()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Original dataset:  {len(original_cats):,} cats + {len(original_dogs):,} dogs = {len(original_cats) + len(original_dogs):,} total\")\n",
    "print(f\"Exclusions:        {len(excluded_files['Cat']):,} cats + {len(excluded_files['Dog']):,} dogs = {len(excluded_files['Cat']) + len(excluded_files['Dog']):,} total\")\n",
    "print(f\"Clean dataset:     {len(clean_cats):,} cats + {len(clean_dogs):,} dogs = {len(clean_cats) + len(clean_dogs):,} total\")\n",
    "print()\n",
    "\n",
    "if all_passed:\n",
    "    print(\"✓ ALL TESTS PASSED - Clean dataset is valid!\")\n",
    "else:\n",
    "    print(\"❌ SOME TESTS FAILED - Check issues above\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catdog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
